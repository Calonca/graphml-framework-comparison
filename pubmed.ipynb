{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch_geometric.utils import softmax\n",
    "import torch_geometric.utils.convert as conv\n",
    "import torch\n",
    "from torch_geometric.nn import GCNConv, GATConv,SAGEConv\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# load the graph from the graphml file\n",
    "def load_graph(file_path):\n",
    "    G = nx.read_graphml(file_path)\n",
    "    return G\n",
    "\n",
    "file_path = 'data/pubmed-diabetes.graphml'\n",
    "# define the classification label\n",
    "classification_label = 'label'\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "G = load_graph(file_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "#Removing not useful attributes\n",
    "for s,d in G.edges:\n",
    "    del G.edges[s,d]['id']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiGraph with 19717 nodes and 44338 edges <class 'networkx.classes.digraph.DiGraph'>\n",
      "('19127292', {'w-rat': 0.0, 'w-common': 0.0, 'w-use': 0.0, 'w-examin': 0.02889892370027422, 'w-pathogenesi': 0.0, 'w-retinopathi': 0.0, 'w-mous': 0.0, 'w-studi': 0.03927472173927795, 'w-anim': 0.0, 'w-model': 0.0, 'w-metabol': 0.0, 'w-abnorm': 0.0, 'w-contribut': 0.0, 'w-develop': 0.0, 'w-investig': 0.0, 'w-mice': 0.0, 'w-2': 0.0051138308462225415, 'w-month': 0.0, 'w-compar': 0.017653254069202904, 'w-obtain': 0.0, 'w-method': 0.0, 'w-induc': 0.0, 'w-6': 0.0, 'w-inject': 0.0, 'w-experiment': 0.0, 'w-normal': 0.0, 'w-diet': 0.0, 'w-30': 0.0, 'w-hyperglycemia': 0.0, 'w-level': 0.0, 'w-lipid': 0.0, 'w-oxid': 0.0, 'w-activ': 0.0, 'w-protein': 0.0, 'w-kinas': 0.0, 'w-c': 0.0, 'w-measur': 0.011734827227009909, 'w-result': 0.005626481865792995, 'w-increas': 0.013080628861391524, 'w-retin': 0.0, 'w-stress': 0.0, 'w-3': 0.009410652924576506, 'w-similar': 0.0, 'w-observ': 0.013638082547296626, 'w-conclus': 0.009595651021257695, 'w-play': 0.0, 'w-import': 0.0, 'w-role': 0.0, 'w-present': 0.0, 'w-p': 0.0, 'w-m': 0.0, 'w-r': 0.0, 'w-muscl': 0.0, 'w-control': 0.0, 'w-chang': 0.0, 'w-dure': 0.0, 'w-lower': 0.0, 'w-higher': 0.013707596952315111, 'w-mass': 0.0, 'w-correl': 0.0, 'w-decreas': 0.0, 'w-determin': 0.0, 'w-concentr': 0.0, 'w-stimul': 0.0, 'w-period': 0.0, 'w-caus': 0.0, 'w-mark': 0.0, 'w-group': 0.0, 'w-evid': 0.018018854082796857, 'w-fast': 0.0, 'w-type': 0.0, 'w-signific': 0.026654784576510108, 'w-differ': 0.0, 'w-ratio': 0.018187833938568296, 'w-suggest': 0.021453823869012026, 'w-degre': 0.0, 'w-occur': 0.0, 'w-vivo': 0.0, 'w-respect': 0.015206016428791635, 'w-dysfunct': 0.02445769293081941, 'w-region': 0.0, 'w-high': 0.0, 'w-appear': 0.0, 'w-sever': 0.0, 'w-affect': 0.0, 'w-cardiovascular': 0.0, 'w-complic': 0.0, 'w-primari': 0.0, 'w-death': 0.0, 'w-patient': 0.0, 'w-clinic': 0.0, 'w-suscept': 0.0, 'w-cardiac': 0.0, 'w-tissu': 0.0, 'w-specif': 0.0, 'w-function': 0.01464439249807633, 'w-defect': 0.0, 'w-possibl': 0.0, 'w-indic': 0.0, 'w-state': 0.0, 'w-onli': 0.0, 'w-bodi': 0.0, 'w-weight': 0.0, 'w-loss': 0.0, 'w-valu': 0.0, 'w-howev': 0.01392805234916936, 'w-4': 0.0, 'w-condit': 0.046675881510411174, 'w-durat': 0.01851450237325145, 'w-8': 0.0, 'w-week': 0.0, 'w-onset': 0.0, 'w-data': 0.013858803228687022, 'w-direct': 0.0, 'w-report': 0.016871029143029966, 'w-provid': 0.018790451745310428, 'w-addit': 0.0, 'w-evalu': 0.0, 'w-sensit': 0.0, 'w-heart': 0.0, 'w-object': 0.0, 'w-mean': 0.0, 'w-blood': 0.0, 'w-glucos': 0.0, 'w-strong': 0.0, 'w-hba': 0.0, 'w-1c': 0.0, 'w-a1c': 0.0, 'w-variabl': 0.0, 'w-independ': 0.04011775265951645, 'w-assess': 0.0, 'w-relat': 0.012703962868216978, 'w-trial': 0.0, 'w-research': 0.01827184529592975, 'w-design': 0.0, 'w-profil': 0.0, 'w-sampl': 0.0, 'w-particip': 0.0, 'w-n': 0.0, 'w-1': 0.037296046599825425, 'w-consist': 0.0, 'w-befor': 0.0, 'w-min': 0.0, 'w-predict': 0.0, 'w-adjust': 0.04485816065696036, 'w-sex': 0.0, 'w-treatment': 0.0, 'w-7': 0.0, 'w-gt': 0.0, 'w-0': 0.0, 'w-larg': 0.0, 'w-influenc': 0.0, 'w-base': 0.0, 'w-standard': 0.0, 'w-14': 0.0, 'w-10': 0.0, 'w-wherea': 0.0, 'w-enhanc': 0.0, 'w-manag': 0.0, 'w-day': 0.0, 'w-secret': 0.0, 'w-cholesterol': 0.0, 'w-insulin': 0.0078880468434901, 'w-24': 0.0, 'w-h': 0.0, 'w-low': 0.0, 'w-rate': 0.0, 'w-fatti': 0.0, 'w-acid': 0.0, 'w-effect': 0.0, 'w-hormon': 0.0, 'w-hepat': 0.0, 'w-contrast': 0.0, 'w-product': 0.0, 'w-major': 0.0, 'w-plasma': 0.0, 'w-current': 0.02489199769729728, 'w-flow': 0.0, 'w-chronic': 0.0, 'w-mechan': 0.0, 'w-test': 0.0, 'w-therefor': 0.0, 'w-analys': 0.0, 'w-mrna': 0.0, 'w-streptozotocin': 0.0, 'w-did': 0.01556637156707304, 'w-15': 0.0, 'w-g': 0.0, 'w-25': 0.02080772022117066, 'w-mmol': 0.0, 'w-l': 0.0, 'w-5': 0.010079301020644037, 'w-reduc': 0.0, 'w-number': 0.0, 'w-densiti': 0.0, 'w-posit': 0.0, 'w-cell': 0.0, 'w-17': 0.0, 'w-mm': 0.0, 'w-18': 0.021136683432121873, 'w-induct': 0.0, 'w-associ': 0.08005494712020127, 'w-express': 0.0, 'w-glycem': 0.0, 'w-respons': 0.0, 'w-therapi': 0.0, 'w-random': 0.0, 'w-initi': 0.0, 'w-ani': 0.0, 'w-singl': 0.0, 'w-new': 0.0, 'w-agent': 0.0, 'w-metformin': 0.0, 'w-medic': 0.0, 'w-glycosyl': 0.0, 'w-hemoglobin': 0.0, 'w-analysi': 0.0, 'w-baselin': 0.040890928004899074, 'w-health': 0.0, 'w-factor': 0.0, 'w-process': 0.0, 'w-care': 0.024305775843801173, 'w-9': 0.0, 'w-01': 0.0, 'w-95': 0.01922789683265175, 'w-interv': 0.0, 'w-ci': 0.06896139646081245, 'w-12': 0.0, 'w-reduct': 0.0, 'w-achiev': 0.0, 'w-target': 0.0, 'w-lt': 0.0, 'w-diseas': 0.011245013629351193, 'w-class': 0.0, 'w-age': 0.0, 'w-obes': 0.0, 'w-renal': 0.0, 'w-improv': 0.0, 'w-progress': 0.0, 'w-noninsulindepend': 0.0, 'w-mellitus': 0.0, 'w-becaus': 0.0, 'w-s': 0.0, 'w-index': 0.0, 'w-hypertens': 0.0, 'w-need': 0.0, 'w-followup': 0.02224156948276848, 'w-year': 0.0, 'w-mg': 0.0, 'w-dl': 0.0, 'w-remain': 0.0, 'w-subject': 0.0, 'w-treat': 0.0, 'w-oral': 0.0, 'w-requir': 0.02225281643368426, 'w-0001': 0.0, 'w-mortal': 0.0, 'w-includ': 0.015287254819072175, 'w-vs': 0.0, 'w-background': 0.01921215945343809, 'w-poor': 0.0, 'w-drug': 0.0, 'w-13': 0.0, 'w-rang': 0.0, 'w-combin': 0.0, 'w-intervent': 0.0, 'w-daili': 0.0, 'w-dose': 0.0, 'w-100': 0.0, 'w-toler': 0.0, 'w-receiv': 0.0, 'w-11': 0.0, 'w-postprandi': 0.0, 'w-kg': 0.0, 'w-hypoglycemia': 0.0, 'w-frequent': 0.0, 'w-event': 0.0, 'w-versus': 0.0, 'w-symptom': 0.0, 'w-incid': 0.03982492465107273, 'w-parent': 0.0, 'w-complex': 0.0, 'w-longterm': 0.0, 'w-inhibitor': 0.0, 'w-peripher': 0.0, 'w-nerv': 0.0, 'w-stz': 0.0, 'w-conduct': 0.0, 'w-demonstr': 0.0, 'w-frequenc': 0.0, 'w-inhibit': 0.0, 'w-neuropathi': 0.0, 'w-pathway': 0.027060284353779763, 'w-shown': 0.0, 'w-time': 0.0, 'w-ii': 0.0, 'w-individu': 0.0, 'w-adult': 0.047288018857577996, 'w-50': 0.0, 'w-60': 0.0, 'w-diagnosi': 0.0, 'w-healthi': 0.0, 'w-follow': 0.0, 'w-young': 0.0, 'w-seen': 0.0, 'w-alter': 0.0, 'w-gene': 0.0, 'w-e': 0.024922786382465763, 'w-identifi': 0.0, 'w-previous': 0.0, 'w-mediat': 0.0, 'w-vascular': 0.023073482295005356, 'w-lipoprotein': 0.0, 'w-involv': 0.0, 'w-phenotyp': 0.0, 'w-confirm': 0.0, 'w-variant': 0.0, 'w-endotheli': 0.0, 'w-potenti': 0.0, 'w-disord': 0.0, 'w-popul': 0.01714682192042379, 'w-nonobes': 0.0, 'w-aim': 0.0, 'w-serum': 0.0, 'w-hba1c': 0.0, 'w-hypoglycaemia': 0.0, 'w-continu': 0.0, 'w-case': 0.0, 'w-impair': 0.035586243104380785, 'w-risk': 0.0505832222599446, 'w-known': 0.0, 'w-men': 0.0, 'w-women': 0.04647243837716785, 'w-40': 0.0, 'w-complet': 0.0, 'w-estim': 0.0, 'w-like': 0.0, 'w-particular': 0.0, 'w-human': 0.0, 'w-character': 0.0, 'w-elev': 0.0, 'w-synthesi': 0.0, 'w-greater': 0.0, 'w-small': 0.0, 'w-reveal': 0.0, 'w-liver': 0.0, 'w-niddm': 0.0, 'w-genet': 0.0, 'w-receptor': 0.0, 'w-growth': 0.0, 'w-pancreat': 0.0, 'w-betacel': 0.0, 'w-molecul': 0.0, 'w-enzym': 0.0, 'w-regul': 0.0, 'w-polymorph': 0.0, 'w-total': 0.0, 'w-allel': 0.0, 'w-02': 0.0, 'w-resist': 0.0, 'w-cpeptid': 0.0, 'w-hypothesi': 0.0, 'w-perform': 0.0, 'w-score': 0.0, 'w-001': 0.0, 'w-05': 0.0, 'w-histori': 0.0, 'w-action': 0.0, 'w-approxim': 0.0, 'w-suppress': 0.0, 'w-glucagon': 0.0, 'w-ml': 0.0, 'w-x': 0.0, 'w-free': 0.0, 'w-peopl': 0.0, 'w-uptak': 0.0, 'w-intens': 0.0, 'w-relationship': 0.0, 'w-prevent': 0.0, 'w-autoimmun': 0.0, 'w-recent': 0.0, 'w-preval': 0.0, 'w-nondiabet': 0.0, 'w-genotyp': 0.0, 'w-conclud': 0.0, 'w-linkag': 0.0, 'w-islet': 0.0, 'w-peptid': 0.0, 'w-form': 0.0, 'w-membran': 0.0, 'w-transgen': 0.0, 'w-failur': 0.0, 'w-isol': 0.0, 'w-negat': 0.0, 'w-earli': 0.0, 'w-famili': 0.0, 'w-chromosom': 0.0, 'w-immun': 0.0, 'w-support': 0.02245209344858597, 'w-16': 0.020504774872551562, 'w-cohort': 0.024443106737423028, 'w-insulindepend': 0.0, 'w-outcom': 0.045634054841286464, 'w-screen': 0.0, 'w-approach': 0.0, 'w-infus': 0.0, 'w-multipl': 0.0, 'w-depend': 0.0, 'w-physic': 0.0, 'w-transport': 0.0, 'w-acut': 0.0, 'w-releas': 0.0, 'w-presenc': 0.0, 'w-glycaem': 0.0, 'w-male': 0.0, 'w-antibodi': 0.0, 'w-femal': 0.0, 'w-pattern': 0.0, 'w-t2dm': 0.0, 'w-promot': 0.0, 'w-fat': 0.0, 'w-d': 0.0, 'w-bmi': 0.0, 'w-haplotyp': 0.0, 'w-triglycerid': 0.0, 'w-interact': 0.0, 'w-marker': 0.0, 'w-describ': 0.0, 'w-area': 0.0, 'w-20': 0.0, 'w-cytokin': 0.0, 'w-bind': 0.0, 'w-bb': 0.0, 'w-alpha': 0.0, 'w-beta': 0.0, 'w-cd4': 0.0, 'w-spontan': 0.0, 'w-vitro': 0.0, 'w-given': 0.0, 'w-basal': 0.0, 'w-protect': 0.0, 'w-pressur': 0.0, 'w-detect': 0.0, 'w-exercis': 0.0, 'w-children': 0.0, 'w-adolesc': 0.0, 'w-life': 0.0, 'w-b': 0.0, 'w-antigen': 0.0, 'w-iddm': 0.0, 'w-american': 0.0, 'w-hla': 0.0, 'w-arteri': 0.0, 'w-nephropathi': 0.0, 'w-review': 0.025228987800241263, 'w-destruct': 0.0, 'w-content': 0.0, 'w-autoantibodi': 0.0, 'w-dm': 0.22510199289253005, 'w-select': 0.045670180934982575, 'w-infect': 0.0, 'w-recipi': 0.0, 'w-intak': 0.0, 'w-placebo': 0.0, 'w-db': 0.0, 'w-pancrea': 0.0, 'w-diagnos': 0.0, 'w-glomerular': 0.0, 'w-albumin': 0.0, 'w-excret': 0.0, 'w-syndrom': 0.0, 'w-t': 0.0, 'w-lymphocyt': 0.0, 'w-produc': 0.0, 'w-coronari': 0.0, 'w-status': 0.05197932433294603, 'w-microalbuminuria': 0.0, 'w-nod': 0.0, 'w-mhc': 0.0, 'w-insul': 0.0, 'w-administr': 0.0, 'w-revers': 0.0, 'w-transplant': 0.0, 'w-graft': 0.0, 'w-t1d': 0.0, 'w-lead': 0.0, 'w-v': 0.0, 'w-dietari': 0.0, 'w-general': 0.0, 'w-macrophag': 0.0, 'w-kidney': 0.0, 'w-urinari': 0.05345886448376969, 'w-myocardi': 0.0, 'w-meal': 0.0, 'w-ica': 0.0, 'w-locus': 0.0, 'w-tcell': 0.0, 'w-depress': 0.09259980388655945, 'w-bone': 0.0, 'w-mutat': 0.0, 'label': 3})\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[1;32mIn [29]\u001B[0m, in \u001B[0;36m<cell line: 8>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      7\u001B[0m labels \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m s,d \u001B[38;5;129;01min\u001B[39;00m G\u001B[38;5;241m.\u001B[39medges:\n\u001B[1;32m----> 9\u001B[0m     labels\u001B[38;5;241m.\u001B[39mappend(\u001B[43mG\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medges\u001B[49m\u001B[43m[\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43md\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlabel\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m)\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(Counter(labels))\n",
      "\u001B[1;31mKeyError\u001B[0m: 'label'"
     ]
    }
   ],
   "source": [
    "print(G, type(G))\n",
    "\n",
    "print(list(G.nodes(data=True))[0])\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "labels = []\n",
    "for s,d in G.edges:\n",
    "    labels.append(G.edges[s,d]['label'])\n",
    "print(Counter(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('19127292', '8886555', {})\n"
     ]
    }
   ],
   "source": [
    "edge = list(G.edges(data=True))[10]\n",
    "print(edge)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert the node attributes into integers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['w-rat', 'w-common', 'w-use', 'w-examin', 'w-pathogenesi', 'w-retinopathi', 'w-mous', 'w-studi', 'w-anim', 'w-model', 'w-metabol', 'w-abnorm', 'w-contribut', 'w-develop', 'w-investig', 'w-mice', 'w-2', 'w-month', 'w-compar', 'w-obtain', 'w-method', 'w-induc', 'w-6', 'w-inject', 'w-experiment', 'w-normal', 'w-diet', 'w-30', 'w-hyperglycemia', 'w-level', 'w-lipid', 'w-oxid', 'w-activ', 'w-protein', 'w-kinas', 'w-c', 'w-measur', 'w-result', 'w-increas', 'w-retin', 'w-stress', 'w-3', 'w-similar', 'w-observ', 'w-conclus', 'w-play', 'w-import', 'w-role', 'w-present', 'w-p', 'w-m', 'w-r', 'w-muscl', 'w-control', 'w-chang', 'w-dure', 'w-lower', 'w-higher', 'w-mass', 'w-correl', 'w-decreas', 'w-determin', 'w-concentr', 'w-stimul', 'w-period', 'w-caus', 'w-mark', 'w-group', 'w-evid', 'w-fast', 'w-type', 'w-signific', 'w-differ', 'w-ratio', 'w-suggest', 'w-degre', 'w-occur', 'w-vivo', 'w-respect', 'w-dysfunct', 'w-region', 'w-high', 'w-appear', 'w-sever', 'w-affect', 'w-cardiovascular', 'w-complic', 'w-primari', 'w-death', 'w-patient', 'w-clinic', 'w-suscept', 'w-cardiac', 'w-tissu', 'w-specif', 'w-function', 'w-defect', 'w-possibl', 'w-indic', 'w-state', 'w-onli', 'w-bodi', 'w-weight', 'w-loss', 'w-valu', 'w-howev', 'w-4', 'w-condit', 'w-durat', 'w-8', 'w-week', 'w-onset', 'w-data', 'w-direct', 'w-report', 'w-provid', 'w-addit', 'w-evalu', 'w-sensit', 'w-heart', 'w-object', 'w-mean', 'w-blood', 'w-glucos', 'w-strong', 'w-hba', 'w-1c', 'w-a1c', 'w-variabl', 'w-independ', 'w-assess', 'w-relat', 'w-trial', 'w-research', 'w-design', 'w-profil', 'w-sampl', 'w-particip', 'w-n', 'w-1', 'w-consist', 'w-befor', 'w-min', 'w-predict', 'w-adjust', 'w-sex', 'w-treatment', 'w-7', 'w-gt', 'w-0', 'w-larg', 'w-influenc', 'w-base', 'w-standard', 'w-14', 'w-10', 'w-wherea', 'w-enhanc', 'w-manag', 'w-day', 'w-secret', 'w-cholesterol', 'w-insulin', 'w-24', 'w-h', 'w-low', 'w-rate', 'w-fatti', 'w-acid', 'w-effect', 'w-hormon', 'w-hepat', 'w-contrast', 'w-product', 'w-major', 'w-plasma', 'w-current', 'w-flow', 'w-chronic', 'w-mechan', 'w-test', 'w-therefor', 'w-analys', 'w-mrna', 'w-streptozotocin', 'w-did', 'w-15', 'w-g', 'w-25', 'w-mmol', 'w-l', 'w-5', 'w-reduc', 'w-number', 'w-densiti', 'w-posit', 'w-cell', 'w-17', 'w-mm', 'w-18', 'w-induct', 'w-associ', 'w-express', 'w-glycem', 'w-respons', 'w-therapi', 'w-random', 'w-initi', 'w-ani', 'w-singl', 'w-new', 'w-agent', 'w-metformin', 'w-medic', 'w-glycosyl', 'w-hemoglobin', 'w-analysi', 'w-baselin', 'w-health', 'w-factor', 'w-process', 'w-care', 'w-9', 'w-01', 'w-95', 'w-interv', 'w-ci', 'w-12', 'w-reduct', 'w-achiev', 'w-target', 'w-lt', 'w-diseas', 'w-class', 'w-age', 'w-obes', 'w-renal', 'w-improv', 'w-progress', 'w-noninsulindepend', 'w-mellitus', 'w-becaus', 'w-s', 'w-index', 'w-hypertens', 'w-need', 'w-followup', 'w-year', 'w-mg', 'w-dl', 'w-remain', 'w-subject', 'w-treat', 'w-oral', 'w-requir', 'w-0001', 'w-mortal', 'w-includ', 'w-vs', 'w-background', 'w-poor', 'w-drug', 'w-13', 'w-rang', 'w-combin', 'w-intervent', 'w-daili', 'w-dose', 'w-100', 'w-toler', 'w-receiv', 'w-11', 'w-postprandi', 'w-kg', 'w-hypoglycemia', 'w-frequent', 'w-event', 'w-versus', 'w-symptom', 'w-incid', 'w-parent', 'w-complex', 'w-longterm', 'w-inhibitor', 'w-peripher', 'w-nerv', 'w-stz', 'w-conduct', 'w-demonstr', 'w-frequenc', 'w-inhibit', 'w-neuropathi', 'w-pathway', 'w-shown', 'w-time', 'w-ii', 'w-individu', 'w-adult', 'w-50', 'w-60', 'w-diagnosi', 'w-healthi', 'w-follow', 'w-young', 'w-seen', 'w-alter', 'w-gene', 'w-e', 'w-identifi', 'w-previous', 'w-mediat', 'w-vascular', 'w-lipoprotein', 'w-involv', 'w-phenotyp', 'w-confirm', 'w-variant', 'w-endotheli', 'w-potenti', 'w-disord', 'w-popul', 'w-nonobes', 'w-aim', 'w-serum', 'w-hba1c', 'w-hypoglycaemia', 'w-continu', 'w-case', 'w-impair', 'w-risk', 'w-known', 'w-men', 'w-women', 'w-40', 'w-complet', 'w-estim', 'w-like', 'w-particular', 'w-human', 'w-character', 'w-elev', 'w-synthesi', 'w-greater', 'w-small', 'w-reveal', 'w-liver', 'w-niddm', 'w-genet', 'w-receptor', 'w-growth', 'w-pancreat', 'w-betacel', 'w-molecul', 'w-enzym', 'w-regul', 'w-polymorph', 'w-total', 'w-allel', 'w-02', 'w-resist', 'w-cpeptid', 'w-hypothesi', 'w-perform', 'w-score', 'w-001', 'w-05', 'w-histori', 'w-action', 'w-approxim', 'w-suppress', 'w-glucagon', 'w-ml', 'w-x', 'w-free', 'w-peopl', 'w-uptak', 'w-intens', 'w-relationship', 'w-prevent', 'w-autoimmun', 'w-recent', 'w-preval', 'w-nondiabet', 'w-genotyp', 'w-conclud', 'w-linkag', 'w-islet', 'w-peptid', 'w-form', 'w-membran', 'w-transgen', 'w-failur', 'w-isol', 'w-negat', 'w-earli', 'w-famili', 'w-chromosom', 'w-immun', 'w-support', 'w-16', 'w-cohort', 'w-insulindepend', 'w-outcom', 'w-screen', 'w-approach', 'w-infus', 'w-multipl', 'w-depend', 'w-physic', 'w-transport', 'w-acut', 'w-releas', 'w-presenc', 'w-glycaem', 'w-male', 'w-antibodi', 'w-femal', 'w-pattern', 'w-t2dm', 'w-promot', 'w-fat', 'w-d', 'w-bmi', 'w-haplotyp', 'w-triglycerid', 'w-interact', 'w-marker', 'w-describ', 'w-area', 'w-20', 'w-cytokin', 'w-bind', 'w-bb', 'w-alpha', 'w-beta', 'w-cd4', 'w-spontan', 'w-vitro', 'w-given', 'w-basal', 'w-protect', 'w-pressur', 'w-detect', 'w-exercis', 'w-children', 'w-adolesc', 'w-life', 'w-b', 'w-antigen', 'w-iddm', 'w-american', 'w-hla', 'w-arteri', 'w-nephropathi', 'w-review', 'w-destruct', 'w-content', 'w-autoantibodi', 'w-dm', 'w-select', 'w-infect', 'w-recipi', 'w-intak', 'w-placebo', 'w-db', 'w-pancrea', 'w-diagnos', 'w-glomerular', 'w-albumin', 'w-excret', 'w-syndrom', 'w-t', 'w-lymphocyt', 'w-produc', 'w-coronari', 'w-status', 'w-microalbuminuria', 'w-nod', 'w-mhc', 'w-insul', 'w-administr', 'w-revers', 'w-transplant', 'w-graft', 'w-t1d', 'w-lead', 'w-v', 'w-dietari', 'w-general', 'w-macrophag', 'w-kidney', 'w-urinari', 'w-myocardi', 'w-meal', 'w-ica', 'w-locus', 'w-tcell', 'w-depress', 'w-bone', 'w-mutat', 'label']\n",
      "{1, 2, 3}\n",
      "501\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "labels = {1:0,2:1,3:2}\n",
    "\n",
    "g_node_attrs = list(list(G.nodes(data=True))[0][1].keys())\n",
    "\n",
    "print(g_node_attrs)\n",
    "\n",
    "classes = set()\n",
    "for id in G.nodes:\n",
    "    classes.add(G.nodes[id][classification_label])\n",
    "for id in G.nodes:\n",
    "    G.nodes[id][classification_label] = labels[G.nodes[id][classification_label]]\n",
    "\n",
    "\n",
    "num_classes = len(classes)\n",
    "\n",
    "print(classes)\n",
    "\n",
    "w_attrs = [attr for attr in g_node_attrs if 'w_' in attr]\n",
    "\n",
    "print(len(g_node_attrs))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{} <class 'dict'>\n",
      "{} <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# delete all the graph attributes, since they are not useful for node classification\n",
    "\n",
    "# print(type(node_attrs))\n",
    "# print(edge_attrs)\n",
    "\n",
    "# graph.graph['node_default'] = True\n",
    "# graph.graph['edge_default'] = True\n",
    "\n",
    "print(G.graph, type(G.graph))\n",
    "\n",
    "if 'node_default' in G.graph:\n",
    "    del G.graph['node_default']\n",
    "if 'edge_default' in G.graph:\n",
    "    del G.graph['edge_default']\n",
    "\n",
    "if 'edge_index' in G.graph:\n",
    "    del G.graph['edge_index']\n",
    "\n",
    "attrs = [attr for attr, _ in G.graph.items()]\n",
    "\n",
    "for attr in attrs:\n",
    "    del G.graph[attr]\n",
    "\n",
    "print(G.graph, type(G.graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges: 44338\n",
      "Data(edge_index=[2, 44338], x=[19717, 501]) <class 'torch_geometric.data.data.Data'>\n"
     ]
    }
   ],
   "source": [
    "data = conv.from_networkx(G, group_node_attrs=g_node_attrs)\n",
    "\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "\n",
    "print(data, type(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Extract the classification label from the nodes attributes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 2.0000],\n",
      "        [0.0000, 0.0000, 0.0088,  ..., 0.0000, 0.0000, 2.0000],\n",
      "        [0.0000, 0.0000, 0.0178,  ..., 0.0000, 0.0000, 2.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 2.0000],\n",
      "        [0.0000, 0.0000, 0.0188,  ..., 0.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0064,  ..., 0.0000, 0.0000, 2.0000]])\n",
      "torch.Size([19717, 501])\n",
      "tensor([[0.0000, 0.0000, 0.0323,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0180,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0486, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "tensor([2., 1., 2.,  ..., 1., 2., 2.])\n",
      "Data(edge_index=[2, 44338], x=[19717, 500], y=[19717])\n"
     ]
    }
   ],
   "source": [
    "print(data.x)\n",
    "\n",
    "# shuffle the data by row\n",
    "data.x = data.x[torch.randperm(data.x.size()[0])]\n",
    "print(data.x.shape)\n",
    "\n",
    "# get the classification attibute from x and assign it to y\n",
    "data.y = data.x[:, -1]\n",
    "# data.y = torch.stack([y[0] for y in data.y])\n",
    "\n",
    "# remove the classification attribute from x\n",
    "data.x = data.x[:, :-1].float()\n",
    "\n",
    "print(data.x)\n",
    "print(data.y)\n",
    "\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define training, validation and test sets randomly"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 44338], x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "\n",
    "# split the data in train, validation and test sets\n",
    "# it adds to data train, val and test masks\n",
    "rns = RandomNodeSplit('random', num_val=0.1, num_test=0.2)\n",
    "\n",
    "data = rns(data)\n",
    "\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "One-hot encode the classification labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]])\n",
      "Data(edge_index=[2, 44338], x=[19717, 500], y=[19717, 3], train_mask=[19717], val_mask=[19717], test_mask=[19717])\n"
     ]
    }
   ],
   "source": [
    "# one hot encode labels\n",
    "data.y = torch.nn.functional.one_hot(data.y.long(), num_classes=num_classes).to(torch.float)\n",
    "\n",
    "print(data.y)\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(data.x.dtype)\n",
    "print(data.y.dtype)\n",
    "print(data.edge_index.dtype)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([    0,     0,     0,  ..., 19280, 19523, 19681]), tensor([    1,  4530,  5212,  ...,  6030,  1043, 18742])]\n"
     ]
    }
   ],
   "source": [
    "print(list(data.edge_index))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def visualize(h, color):\n",
    "    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(500, 16)\n",
      "  (conv2): GCNConv(16, 3)\n",
      ")\n",
      "tensor([[0.3333, 0.3333, 0.3333],\n",
      "        [0.3319, 0.3335, 0.3346],\n",
      "        [0.3328, 0.3345, 0.3328],\n",
      "        ...,\n",
      "        [0.3260, 0.3403, 0.3337],\n",
      "        [0.3315, 0.3322, 0.3363],\n",
      "        [0.3364, 0.3322, 0.3315]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_features, hidden_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234567)\n",
    "        self.conv1 = GCNConv(input_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.4, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.4, training=self.training)\n",
    "        # x = softmax(x)\n",
    "        # x = F.log_softmax(x, dim=1)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "in_features = data.x.shape[1]\n",
    "\n",
    "model = GCN(input_features=in_features, hidden_channels=16)\n",
    "model.eval()\n",
    "print(model)\n",
    "\n",
    "out = model(data.x, data.edge_index)\n",
    "#visualize(out, color=data.y)\n",
    "print(out)\n",
    "\n",
    "model = GCN(input_features=in_features, hidden_channels=16)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, input_features, hidden_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234567)\n",
    "        self.conv1 = SAGEConv(input_features, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.4, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.4, training=self.training)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "in_features = data.x.shape[1]\n",
    "\n",
    "model = SAGE(input_features=in_features, hidden_channels=16)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT(\n",
      "  (conv1): GATConv(3703, 8, heads=8)\n",
      "  (conv2): GATConv(64, 6, heads=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, heads):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234567)\n",
    "\n",
    "        self.hid = 8\n",
    "        self.in_head = 8\n",
    "        self.out_head = 1\n",
    "\n",
    "        self.conv1 = GATConv(in_features, self.hid, heads=self.in_head, dropout=0.6)\n",
    "        self.conv2 = GATConv(self.hid*self.in_head, num_classes, concat=False,\n",
    "                             heads=self.out_head, dropout=0.6)\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "model = GAT(hidden_channels=8, heads=8)\n",
    "print(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "def train():\n",
    "      model.train()\n",
    "      optimizer.zero_grad()  # Clear gradients.\n",
    "      out = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "      loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "      val_loss = criterion(out[data.val_mask], data.y[data.val_mask])  # Compute the loss solely based on the training nodes.\n",
    "      loss.backward()  # Derive gradients.\n",
    "      optimizer.step()  # Update parameters based on gradients.\n",
    "      return loss, val_loss\n",
    "\n",
    "\n",
    "def test(models, ds='test'):\n",
    "      models.eval()\n",
    "      out = models(data.x, data.edge_index)\n",
    "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "      if ds == 'test':\n",
    "            outs = out[data.test_mask]\n",
    "            mask = data.test_mask\n",
    "            d_set = pred[data.test_mask]\n",
    "            label_set = data.y[data.test_mask]\n",
    "      elif ds == 'val':\n",
    "            outs = out[data.val_mask]\n",
    "            mask = data.val_mask\n",
    "            d_set = pred[data.val_mask]\n",
    "            label_set = data.y[data.val_mask]\n",
    "      else:\n",
    "            outs = out[data.train_mask]\n",
    "            mask = data.train_mask\n",
    "            d_set = pred[data.train_mask]\n",
    "            label_set = data.y[data.train_mask]\n",
    "      # print(outs)\n",
    "      # print(label_set)\n",
    "      label_set = label_set.argmax(dim=1)\n",
    "      test_correct = d_set == label_set  # Check against ground-truth labels.\n",
    "      test_acc = int(test_correct.sum()) / int(mask.sum())  # Derive ratio of correct predictions.\n",
    "      return test_acc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 1.1065, Val Loss: 1.1086\n",
      "Epoch: 002, Loss: 1.0848, Val Loss: 1.0941\n",
      "Epoch: 003, Loss: 1.0495, Val Loss: 1.0927\n",
      "Epoch: 004, Loss: 1.0034, Val Loss: 1.0866\n",
      "Epoch: 005, Loss: 1.0200, Val Loss: 1.0882\n",
      "Epoch: 006, Loss: 0.9548, Val Loss: 1.0834\n",
      "Epoch: 007, Loss: 0.9216, Val Loss: 1.0909\n",
      "Epoch: 008, Loss: 0.9549, Val Loss: 1.0811\n",
      "Epoch: 009, Loss: 1.0102, Val Loss: 1.0757\n",
      "Epoch: 010, Loss: 0.9151, Val Loss: 1.0740\n",
      "Epoch: 011, Loss: 0.9079, Val Loss: 1.0669\n",
      "Epoch: 012, Loss: 0.8894, Val Loss: 1.0638\n",
      "Epoch: 013, Loss: 0.9315, Val Loss: 1.0724\n",
      "Epoch: 014, Loss: 0.9266, Val Loss: 1.0612\n",
      "Epoch: 015, Loss: 0.9370, Val Loss: 1.0593\n",
      "Epoch: 016, Loss: 0.9242, Val Loss: 1.0549\n",
      "Epoch: 017, Loss: 0.9405, Val Loss: 1.0635\n",
      "Epoch: 018, Loss: 0.9344, Val Loss: 1.0616\n",
      "Epoch: 019, Loss: 0.9445, Val Loss: 1.0556\n",
      "Epoch: 020, Loss: 0.8803, Val Loss: 1.0628\n",
      "Epoch: 021, Loss: 0.8895, Val Loss: 1.0671\n",
      "Epoch: 022, Loss: 0.9447, Val Loss: 1.0669\n",
      "Epoch: 023, Loss: 0.8951, Val Loss: 1.0600\n",
      "Epoch: 024, Loss: 0.9145, Val Loss: 1.0537\n",
      "Epoch: 025, Loss: 0.9153, Val Loss: 1.0625\n",
      "Epoch: 026, Loss: 0.8887, Val Loss: 1.0583\n",
      "Epoch: 027, Loss: 0.9234, Val Loss: 1.0494\n",
      "Epoch: 028, Loss: 0.8726, Val Loss: 1.0566\n",
      "Epoch: 029, Loss: 0.9380, Val Loss: 1.0613\n",
      "Epoch: 030, Loss: 0.9196, Val Loss: 1.0629\n",
      "Epoch: 031, Loss: 0.8823, Val Loss: 1.0622\n",
      "Epoch: 032, Loss: 0.8987, Val Loss: 1.0616\n",
      "Epoch: 033, Loss: 0.8765, Val Loss: 1.0564\n",
      "Epoch: 034, Loss: 0.9491, Val Loss: 1.0566\n",
      "Epoch: 035, Loss: 0.8594, Val Loss: 1.0579\n",
      "Epoch: 036, Loss: 0.9010, Val Loss: 1.0519\n",
      "Epoch: 037, Loss: 0.9501, Val Loss: 1.0560\n",
      "Epoch: 038, Loss: 0.8796, Val Loss: 1.0564\n",
      "Epoch: 039, Loss: 0.9184, Val Loss: 1.0475\n",
      "Epoch: 040, Loss: 0.9743, Val Loss: 1.0640\n",
      "Epoch: 041, Loss: 0.9088, Val Loss: 1.0541\n",
      "Epoch: 042, Loss: 0.8801, Val Loss: 1.0564\n",
      "Epoch: 043, Loss: 0.8948, Val Loss: 1.0598\n",
      "Epoch: 044, Loss: 0.9158, Val Loss: 1.0638\n",
      "Epoch: 045, Loss: 0.9019, Val Loss: 1.0619\n",
      "Epoch: 046, Loss: 0.9049, Val Loss: 1.0613\n",
      "Epoch: 047, Loss: 0.8843, Val Loss: 1.0580\n",
      "Epoch: 048, Loss: 0.8976, Val Loss: 1.0650\n",
      "Epoch: 049, Loss: 0.9005, Val Loss: 1.0679\n",
      "Epoch: 050, Loss: 0.9234, Val Loss: 1.0742\n",
      "Epoch: 051, Loss: 0.8978, Val Loss: 1.0715\n",
      "Epoch: 052, Loss: 0.9705, Val Loss: 1.0540\n",
      "Epoch: 053, Loss: 0.9263, Val Loss: 1.0622\n",
      "Epoch: 054, Loss: 0.9077, Val Loss: 1.0613\n",
      "Epoch: 055, Loss: 0.9185, Val Loss: 1.0613\n",
      "Epoch: 056, Loss: 0.9715, Val Loss: 1.0589\n",
      "Epoch: 057, Loss: 0.9473, Val Loss: 1.0594\n",
      "Epoch: 058, Loss: 0.8918, Val Loss: 1.0568\n",
      "Epoch: 059, Loss: 0.9386, Val Loss: 1.0565\n",
      "Epoch: 060, Loss: 0.9148, Val Loss: 1.0574\n",
      "Epoch: 061, Loss: 0.9753, Val Loss: 1.0586\n",
      "Epoch: 062, Loss: 0.8875, Val Loss: 1.0545\n",
      "Epoch: 063, Loss: 0.9182, Val Loss: 1.0481\n",
      "Epoch: 064, Loss: 0.9423, Val Loss: 1.0591\n",
      "Epoch: 065, Loss: 0.8880, Val Loss: 1.0558\n",
      "Epoch: 066, Loss: 0.8873, Val Loss: 1.0586\n",
      "Epoch: 067, Loss: 0.8871, Val Loss: 1.0659\n",
      "Epoch: 068, Loss: 0.9128, Val Loss: 1.0562\n",
      "Epoch: 069, Loss: 0.8958, Val Loss: 1.0518\n",
      "Epoch: 070, Loss: 0.9271, Val Loss: 1.0466\n",
      "Epoch: 071, Loss: 0.9427, Val Loss: 1.0588\n",
      "Epoch: 072, Loss: 0.9084, Val Loss: 1.0455\n",
      "Epoch: 073, Loss: 0.9205, Val Loss: 1.0479\n",
      "Epoch: 074, Loss: 0.9273, Val Loss: 1.0498\n",
      "Epoch: 075, Loss: 0.9294, Val Loss: 1.0556\n",
      "Epoch: 076, Loss: 0.8774, Val Loss: 1.0565\n",
      "Epoch: 077, Loss: 0.9169, Val Loss: 1.0494\n",
      "Epoch: 078, Loss: 0.9449, Val Loss: 1.0544\n",
      "Epoch: 079, Loss: 0.9427, Val Loss: 1.0551\n",
      "Epoch: 080, Loss: 0.9208, Val Loss: 1.0524\n",
      "Epoch: 081, Loss: 0.9413, Val Loss: 1.0515\n",
      "Epoch: 082, Loss: 0.9150, Val Loss: 1.0513\n",
      "Epoch: 083, Loss: 0.9685, Val Loss: 1.0465\n",
      "Epoch: 084, Loss: 0.8659, Val Loss: 1.0549\n",
      "Epoch: 085, Loss: 0.9023, Val Loss: 1.0475\n",
      "Epoch: 086, Loss: 0.8917, Val Loss: 1.0477\n",
      "Epoch: 087, Loss: 0.9431, Val Loss: 1.0489\n",
      "Epoch: 088, Loss: 0.9094, Val Loss: 1.0669\n",
      "Epoch: 089, Loss: 0.9261, Val Loss: 1.0555\n",
      "Epoch: 090, Loss: 0.9465, Val Loss: 1.0430\n",
      "Epoch: 091, Loss: 0.9011, Val Loss: 1.0549\n",
      "Epoch: 092, Loss: 0.9205, Val Loss: 1.0564\n",
      "Epoch: 093, Loss: 0.9087, Val Loss: 1.0593\n",
      "Epoch: 094, Loss: 0.9251, Val Loss: 1.0563\n",
      "Epoch: 095, Loss: 0.9152, Val Loss: 1.0595\n",
      "Epoch: 096, Loss: 0.9186, Val Loss: 1.0520\n",
      "Epoch: 097, Loss: 0.9526, Val Loss: 1.0489\n",
      "Epoch: 098, Loss: 0.9378, Val Loss: 1.0499\n",
      "Epoch: 099, Loss: 0.9244, Val Loss: 1.0558\n",
      "Epoch: 100, Loss: 0.9070, Val Loss: 1.0575\n",
      "Train Accuracy: 0.6667\n",
      "Val Accuracy: 0.4767\n",
      "Test Accuracy: 0.4854\n"
     ]
    },
    {
     "data": {
      "text/plain": "SAGE(\n  (conv1): SAGEConv(500, 16, aggr=mean)\n  (conv2): SAGEConv(16, 3, aggr=mean)\n)"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_patience = 40\n",
    "patience = start_patience\n",
    "best_val_loss = 10000\n",
    "best_model = model\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    if patience == 0:\n",
    "        break\n",
    "    loss, val_loss = train()\n",
    "    if val_loss <= best_val_loss:\n",
    "        patience = start_patience\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "    else:\n",
    "        patience -= 1\n",
    "\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "\n",
    "train_acc = test(best_model, 'train')\n",
    "val_acc = test(best_model, 'val')\n",
    "test_acc = test(best_model)\n",
    "\n",
    "print(f'Train Accuracy: {train_acc:.4f}')\n",
    "print(f'Val Accuracy: {val_acc:.4f}')\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# out = model(data.x, data.edge_index)\n",
    "# visualize(out, color=data.y)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
